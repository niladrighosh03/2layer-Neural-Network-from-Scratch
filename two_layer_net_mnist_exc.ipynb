{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a simple two layers neural network\n",
    "In this exercise we will develop a two neural network with fully-connected layers to perform classification, and test it out on the MNIST dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-----------------------------------------------------------------------------\n",
    "A simple two layers neural network for handwritten digit classification (MNIST)\n",
    "-----------------------------------------------------------------------------\n",
    "AUTHOR: Soumitra Samanta (soumitra.samanta@gm.rkmvu.ac.in)\n",
    "-----------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "from first_nn_exc import *\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read MNIST data:\n",
    "You can download the data from [here](https://www.kaggle.com/datasets/hojjatk/mnist-dataset). There are many [way](https://stackoverflow.com/questions/40427435/extract-images-from-idx3-ubyte-file-or-gzip-via-python) you can read the MNIST data. Here is a [way](https://stackoverflow.com/a/62781370) to read all the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data (X) size: (60000, 28, 28), and labels (Y) size: (60000,)\n",
      "Test data (X) size: (10000, 28, 28), and labels (Y) size: (10000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def read_images(filename):\n",
    "    \"\"\"Read MNIST images\"\"\"\n",
    "    \n",
    "    with gzip.open(filename, 'r') as f:\n",
    "        # first 4 bytes is a magic number\n",
    "        magic_number = int.from_bytes(f.read(4), 'big')\n",
    "        # second 4 bytes is the number of images\n",
    "        image_count = int.from_bytes(f.read(4), 'big')\n",
    "        # third 4 bytes is the row count\n",
    "        row_count = int.from_bytes(f.read(4), 'big')\n",
    "        # fourth 4 bytes is the column count\n",
    "        column_count = int.from_bytes(f.read(4), 'big')\n",
    "        # rest is the image pixel data, each pixel is stored as an unsigned byte\n",
    "        # pixel values are 0 to 255\n",
    "        image_data = f.read()\n",
    "        images = np.frombuffer(image_data, dtype=np.uint8).reshape((image_count, row_count, column_count))\n",
    "        \n",
    "    return images\n",
    "\n",
    "def read_labels(filename):\n",
    "    \"\"\"Read MNIST labels\"\"\"\n",
    "    \n",
    "    with gzip.open(filename, 'r') as f:\n",
    "        # first 4 bytes is a magic number\n",
    "        magic_number = int.from_bytes(f.read(4), 'big')\n",
    "        # second 4 bytes is the number of labels\n",
    "        label_count = int.from_bytes(f.read(4), 'big')\n",
    "        # rest is the label data, each label is stored as unsigned byte\n",
    "        # label values are 0 to 9\n",
    "        label_data = f.read()\n",
    "        labels = np.frombuffer(label_data, dtype=np.uint8)\n",
    "        \n",
    "    return labels\n",
    "\n",
    "\n",
    "dataset_path = '/Users/soumitra/Library/CloudStorage/OneDrive-Personal/Documents/SS_PERSONAL/SS_TEACHING/RKMVERI/data_experiment/mnist/'\n",
    "\n",
    "train_image_filename = ''.join([dataset_path, 'train-images-idx3-ubyte.gz'])\n",
    "train_label_filename = ''.join([dataset_path, 'train-labels-idx1-ubyte.gz'])\n",
    "\n",
    "test_image_filename = ''.join([dataset_path, 't10k-images-idx3-ubyte.gz'])\n",
    "test_label_filename = ''.join([dataset_path, 't10k-labels-idx1-ubyte.gz'])\n",
    "\n",
    "train_images = read_images(train_image_filename)\n",
    "train_labels = read_labels(train_label_filename)\n",
    "\n",
    "print('Train data (X) size: {}, and labels (Y) size: {}' .format(train_images.shape, train_labels.shape))\n",
    "\n",
    "test_images = read_images(test_image_filename)\n",
    "test_labels = read_labels(test_label_filename)\n",
    "\n",
    "print('Test data (X) size: {}, and labels (Y) size: {}' .format(test_images.shape, test_labels.shape))\n",
    "\n",
    "\n",
    "\n",
    "rand_ids = np.random.choice(train_images.shape[0])\n",
    "plt.imshow(train_images[rand_ids, :, :], cmap='gray')\n",
    "plt.title('class-'+str(train_labels[rand_ids]))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS-CHECK: Create a validation data from training data (10%) and transform the data in $\\mathbf{R}^d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val data (X) size: (5999, 28, 28), and labels (Y) size: (5999,)\n",
      "After reshape\n",
      "\n",
      "Train data (X) size: (59990, 784), and labels (Y) size: (59990,)\n",
      "Val data (X) size: (5999, 784), and labels (Y) size: (5999,)\n",
      "Test data (X) size: (10000, 784), and labels (Y) size: (10000,)\n"
     ]
    }
   ],
   "source": [
    "val_data_ration = 0.1\n",
    "class_ids = list(set(train_labels))\n",
    "val_ids = []\n",
    "for cl in class_ids:\n",
    "    temp_val_index = np.where(train_labels==cl)\n",
    "    val_ids.extend(list(np.random.permutation(temp_val_index[0])[:round(temp_val_index[0].shape[0]*val_data_ration)]))\n",
    "# print(val_ids)     \n",
    "val_images = train_images[val_ids, :, :]  \n",
    "val_labels = train_labels[val_ids]  \n",
    "print('Val data (X) size: {}, and labels (Y) size: {}' .format(val_images.shape, val_labels.shape))\n",
    "\n",
    "train_ids = [i for i in range(train_labels.shape[0]) if i not in val_labels]\n",
    "revised_train_images = train_images[train_ids, :, :]  \n",
    "revised_train_labels = train_labels[train_ids]  \n",
    " \n",
    "X_train = revised_train_images.reshape(revised_train_images.shape[0], -1)\n",
    "Y_train = revised_train_labels.reshape(-1)\n",
    "X_val = val_images.reshape(val_images.shape[0], -1)\n",
    "Y_val = val_labels.reshape(-1)\n",
    "X_test = test_images.reshape(test_images.shape[0], -1)\n",
    "Y_test = test_labels.reshape(-1)\n",
    "\n",
    "print('After reshape\\n')\n",
    "print('Train data (X) size: {}, and labels (Y) size: {}' .format(X_train.shape, Y_train.shape))\n",
    "print('Val data (X) size: {}, and labels (Y) size: {}' .format(X_val.shape, Y_val.shape))\n",
    "print('Test data (X) size: {}, and labels (Y) size: {}' .format(X_test.shape, Y_test.shape))\n",
    "\n",
    "\n",
    "\n",
    "                        \n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a network\n",
    "To train our network we will use Stochastic Gradient Decent (SGD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dimension = X_train.shape[1]\n",
    "num_hidden_nodes = 50\n",
    "num_classes = 10\n",
    "net = FirstNN(data_dimension, num_hidden_nodes, num_classes)\n",
    "\n",
    "# Train the network\n",
    "stats = net.train(X_train, Y_train, X_val, Y_val, \n",
    "                  num_iters=10000,\n",
    "                  num_epoch=30,\n",
    "                  batch_size=200, \n",
    "                  learning_rate=1e-2, \n",
    "                  verbose=True\n",
    "                 )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the train set\n",
    "Y_train_pred = net.predict(X_train, best_param=True)\n",
    "train_acc = 100*(Y_train_pred == Y_train).mean()\n",
    "print('Train accuracy: {:.2f}' .format(train_acc))\n",
    "\n",
    "# Predict on the validation set\n",
    "Y_val_pred = net.predict(X_val, best_param=True)\n",
    "val_acc = 100*(Y_val_pred == Y_val).mean()\n",
    "print('Validation accuracy: {:.2f}' .format(val_acc))\n",
    "\n",
    "# Predict on the test set\n",
    "Y_test_pred = net.predict(X_test, best_param=True)\n",
    "test_acc = 100*(Y_test_pred == Y_test).mean()\n",
    "print('Test accuracy: {:.2f}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss function and train / validation accuracies\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(stats['loss_history_batch'])\n",
    "plt.title('Loss history batch wise')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(linestyle='--')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(stats['loss_history_epoch'])\n",
    "plt.title('Loss history epoch wise')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(linestyle='--')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(stats['train_acc_history'], label='train')\n",
    "plt.plot(stats['val_acc_history'], label='val')\n",
    "plt.title('Classification accuracy history')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Clasification accuracy')\n",
    "plt.grid(linestyle='--')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Tune your hyperparameters:\n",
    "    - Learning rate:\n",
    "    - Number of nodes in hidden layer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_net = None # store the best model into this \n",
    "\n",
    "#################################################################################\n",
    "# TODO: Tune hyperparameters using the validation set. Store your best trained  #\n",
    "# model in best_net.                                                            #\n",
    "#################################################################################\n",
    "results = {}\n",
    "best_val = 0\n",
    "best_net = None\n",
    "learning_rates = [1e-3, 5e-3, 7e-3, 1e-2, 5e-2, 1e-1]\n",
    "num_hidden_nodes = [30, 50, 60, 70, 100]\n",
    "num_classes = 10\n",
    "num_iters = 5000\n",
    "num_epoch = 30\n",
    "batch_size = 256\n",
    "# Perform hyperparameter tuning\n",
    "for lr in learning_rates:\n",
    "    for num_hidden_nodes in num_hidden_nodes_list:\n",
    "        print(f\"Training model with learning rate: {lr} and hidden layer size: {num_hidden_nodes}\")\n",
    "\n",
    "        # Initialize network\n",
    "        net = FirstNN(input_dims=X_train.shape[1], num_nodes_lr1=num_hidden_nodes, num_classes=num_classes)\n",
    "\n",
    "        # Train the model\n",
    "        stats = net.train(X_train, Y_train, X_val, Y_val, \n",
    "                          num_iters=num_iters,\n",
    "                          num_epoch=num_epoch,\n",
    "                          batch_size=batch_size, \n",
    "                          learning_rate=lr, \n",
    "                          verbose=False)\n",
    "\n",
    "        # Compute validation accuracy\n",
    "        Y_val_pred = net.predict(X_val, best_param=True)\n",
    "        val_acc = 100 * np.mean(Y_val_pred == Y_val)\n",
    "\n",
    "        # Store results\n",
    "        results[(num_hidden_nodes, lr)] = val_acc\n",
    "\n",
    "        # Update best model if current model is better\n",
    "        if val_acc > best_val:\n",
    "            best_val = val_acc\n",
    "            best_net = copy.deepcopy(net)  # Store the best model\n",
    "\n",
    "\n",
    "# Print best results.\n",
    "print('Best validation accuracy achieved during cross-validation: {:.2f} for #hdnn: {}, lr: {}' .format(best_val, best_net.best_params['W1'].shape[1], best_net.learning_rate))\n",
    "#################################################################################\n",
    "#                               END OF YOUR CODE                                #\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the train set\n",
    "Y_train_pred = best_net.predict(X_train, best_param=True)\n",
    "train_acc = 100*(Y_train_pred == Y_train).mean()\n",
    "print('Train accuracy: {:.2f}' .format(train_acc))\n",
    "\n",
    "# Predict on the validation set\n",
    "Y_val_pred = best_net.predict(X_val, best_param=True)\n",
    "val_acc = 100*(Y_val_pred == Y_val).mean()\n",
    "print('Validation accuracy: {:.2f}' .format(val_acc))\n",
    "\n",
    "# Predict on the test set\n",
    "Y_test_pred = best_net.predict(X_test, best_param=True)\n",
    "test_acc = 100*(Y_test_pred == Y_test).mean()\n",
    "print('Test accuracy: {:.2f}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condapy310",
   "language": "python",
   "name": "condapy310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
